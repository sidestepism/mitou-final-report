\section{実装の概要}

本プロジェクトは，視覚（光学的）情報を適切な方法で音響化することにより，聴覚による空間知覚を可能にするデバイス「Sight」を開発することを目標とするものである．
九ヶ月間のプロジェクト実施期間を通じて我々は，「Sight」装着状態でより高度な空間知覚タスクの実行を可能にすべく，ヒトの視聴覚の特性に関する調査・検討を重ねつつ複数の視聴覚変換手法を開発した．
本セクションでは，各段階のバージョンにおいて提案された変換手法について，その技術的詳細と上記目標に対する実現度の評価を述べる．

いずれのバージョンにおいても，「Sight」は搭載した光学的センサからの入力（視覚情報）をパラメータ化し，このパラメータを用いてソフトウェアシンセサイザにより音響を合成するという処理のフローを採用する．
従って，視覚情報のパラメータ化，音響のパラメータ表現，および両者のパラメータの対応付けという三種類の変換の組み合わせにより入出力が対応付けられることとなる．
以下，第一の変換にあたる「外界の認識」と第二・第三の変換にあたる「音響合成戦略」それぞれに分けて提案手法を詳説する．

また，本プロジェクトでは視聴覚変換手法のソフトウェア実装の他，装着用のハードウェアもデザイン・製作した．
本セクションでは「Sight」デバイスのハードウェアについても開発の経緯及び工夫点を解説する．

\subsection{外界の認識}
\subsubsection{バージョン1: 低次の特徴点・局所特徴量(SURF)の分布}
\subsubsection{バージョン2: 一般物体認識のDNNを用いたモデル}
\subsubsection{バージョン3: 視野内数点の深さ情報}
\subsubsection{バージョン4: 平面配置から行為可能性を解析}

\subsection{音響合成戦略}
\subsubsection{Granular Synthesisを用いた音響合成}
\subsubsection{Corpus-based Granular Synthesis}
\subsubsection{楽器，立体音響}

\subsection{ハードウェア}

